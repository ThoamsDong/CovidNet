{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GO corona GO.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMAMgadYNwqsuEhQsL5Krir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smaranjitghose/CovidNet/blob/master/coronanet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUw5vgXEz-Il",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9dd02b1b-272f-4d10-979c-3e3c084f456b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiFn1-FfslAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f52a3e5-f142-420a-86ab-02fda67fc5ff"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/content/drive/My Drive/Something out of bounds',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "H = model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=100)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 input_10\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_8\n",
            "88 dense_33\n",
            "89 dense_34\n",
            "90 dense_35\n",
            "91 dense_36\n",
            "Found 50 images belonging to 2 classes.\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.7719 - acc: 0.5556\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 2.2192 - acc: 0.5312\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 1.2737 - acc: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.0628 - acc: 0.9688\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.0335 - acc: 1.0000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.0053 - acc: 1.0000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 5.3143e-04 - acc: 1.0000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 6.4718e-05 - acc: 1.0000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 3.5449e-04 - acc: 1.0000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 7.0851e-05 - acc: 1.0000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 9.5857e-06 - acc: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 7.2852e-06 - acc: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 2.6458e-06 - acc: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 2.5761e-04 - acc: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 3.7651e-06 - acc: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 2.7381e-07 - acc: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 3.0175e-05 - acc: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 1.8626e-07 - acc: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 7.2009e-05 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 3.6956e-06 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 1s 547ms/step - loss: 7.3965e-05 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.8626e-07 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.6060e-06 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 4.3887e-06 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 1.7695e-07 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 5.8943e-07 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 1.2666e-07 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 1.5299e-06 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 4.9174e-07 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 3.6155e-06 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 1s 525ms/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 2.1998e-06 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 1.2666e-07 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 2.1855e-07 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 1.2293e-07 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 425ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.3925 - acc: 0.9688\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 1.8876 - acc: 0.7778\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 4.3265e-04 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 1s 512ms/step - loss: 0.1240 - acc: 0.9444\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.8605 - acc: 0.8438\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0133 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 6.5796e-04 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.3720 - acc: 0.9688\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 4.2455e-05 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 2.6726e-05 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0587 - acc: 0.9688\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 1.6963e-05 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 6.3181e-04 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 4.7683e-05 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 422ms/step - loss: 1.4541e-04 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0194 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.3923e-05 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 3.2215e-04 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 1s 613ms/step - loss: 1.0509 - acc: 0.8333\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 4.0271e-04 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0092 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1292 - acc: 0.9062\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 0.0378 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1697 - acc: 0.9375\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.0115 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0142 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 7.5411e-04 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 9.2083e-04 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 8.7750e-04 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 3.0679e-05 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 5.7256e-06 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0602 - acc: 0.9688\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 1.1081e-05 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 2.0713e-06 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 4.7552e-06 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 1s 542ms/step - loss: 2.6052e-04 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 8.8103e-07 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 1.3495e-05 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 3.0687e-05 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 4.5897e-06 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 2.2121e-05 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 6.1396e-06 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 3.5578e-06 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcM7vAWw7IbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a89228e5-eac6-4ea5-abfe-39d8b31cbb11"
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPmJbxDh72vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmWZFRMA8nXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "1ac6d698-8b0e-464b-e34a-8203cb83403e"
      },
      "source": [
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       1.00      0.80      0.89         5\n",
            "      normal       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.90        10\n",
            "   macro avg       0.92      0.90      0.90        10\n",
            "weighted avg       0.92      0.90      0.90        10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbnECuZp8pyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpcM4K_o8uTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "81e2c573-c04c-4c99-9014-98f80012904f"
      },
      "source": [
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 1]\n",
            " [0 5]]\n",
            "acc: 0.9000\n",
            "sensitivity: 0.8000\n",
            "specificity: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e_xFYRx8v6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}